@article{Greene2017,
abstract = {Figure 1: Fast Lightweight Mesh Estimation: FLaME generates 3D mesh reconstructions from monocular images in real-time onboard computationally constrained platforms. The key to the approach is a graph-based variational optimization framework that allows for the mesh to be efficiently smoothed and refined. The top row of images (from left to right) show the meshes computed onboard a small autonomous robot flying at 3.5 meters-per-second as it avoids a tree. The bottom row shows the current frame (left), the collision-free plan in pink (middle), and the dense depthmap generated from the mesh (right) for each timestep along the approach. Abstract We propose a lightweight method for dense online monocular depth estimation capable of reconstructing 3D meshes on computationally constrained platforms. Our main contribution is to pose the reconstruction problem as a non-local variational optimization over a time-varying De-launay graph of the scene geometry, which allows for an efficient, keyframeless approach to depth estimation. The graph can be tuned to favor reconstruction quality or speed and is continuously smoothed and augmented as the camera explores the scene. Unlike keyframe-based approaches, the optimized surface is always available at the current pose, which is necessary for low-latency obstacle avoidance. FLaME (Fast Lightweight Mesh Estimation) can gener-ate mesh reconstructions at upwards of 230 Hz using less than one Intel i7 CPU core, which enables operation on size, weight, and power-constrained platforms. We present results from both benchmark datasets and experiments run-ning FLaME in-the-loop onboard a small flying quadrotor.},
annote = {This paper presents a novel dense monocular depth estimation algorithm capable of reconstructing geometric meshes on computationally constrained platforms. FLaME refrmulates the reconstruciton problem as a variational smoothing problem over a time-varying Delaunay graph, which allows both for efficient, incremental smoothing of noisy depth estimates and low-latency mesh estimation.
The mesh is interpreted as a graph over which a convec optimization problem is set to perform the smoothing.},
author = {Greene, W Nicholas and Roy, Nicholas},
file = {:home/andreasziegler/Downloads/FLaME$\backslash$: Fast Lightweight Mesh Estimation using Variational Smoothing on.pdf:pdf},
journal = {IEEE International Conference on Computer Vision (ICCV)},
pages = {4686--4694},
title = {{FLaME: Fast Lightweight Mesh Estimation using Variational Smoothing on Delaunay Graphs}},
url = {http://groups.csail.mit.edu/rrg/papers/greene{\_}iccv17.pdf},
year = {2017}
}
@inproceedings{Weiss2011,
abstract = {Recent development showed that Micro Aerial Vehicles (MAVs) are nowadays capable of autonomously take off at one point and land at another using only one single camera as exteroceptive sensor. During the flight and landing phase the MAV and user have, however, little knowledge about the whole terrain and potential obstacles. In this paper we show a new solution for a real-time dense 3D terrain reconstruction. This can be used for efficient unmanned MAV terrain exploration and yields a solid base for standard autonomous obstacle avoidance algorithms and path planners. Our approach is based on a textured 3D mesh on sparse 3D point features of the scene. We use the same feature points to localize and control the vehicle in the 3D space as we do for building the 3D terrain reconstruction mesh. This enables us to reconstruct the terrain without significant additional cost and thus in real-time. Experiments show that the MAV is easily guided through an unknown, GPS denied environment. Obstacles are recognized in the iteratively built 3D terrain reconstruction and are thus well avoided.},
annote = {This work presents a method to reconstruct in real time an intuitive dense textured 3D mesh map out of a sparse point cloud from any fiben visulSLAM algorithm. The algorithm shows successful removal of point feature outliers aid of median filtering the mesh. The real time map construction allows to iteratively refine, imporove and extend the map. As the mesh represents a conservative boundary to objects and to non traversable areas it can directly be used in standard obstacle avoidance and path planning algorithms.},
author = {Weiss, Stephan and Achtelik, Markus and Kneip, Laurent and Scaramuzza, Davide and Siegwart, Roland},
booktitle = {Journal of Intelligent and Robotic Systems: Theory and Applications},
doi = {10.1007/s10846-010-9491-y},
file = {:home/andreasziegler/Downloads/Intuitive 3D Maps for MAV Terrain Exploration.pdf:pdf},
isbn = {0921-0296},
issn = {09210296},
keywords = {3D map generation,MAV navigation,Mesh map,Obstacle avoidance,Terrain exploration},
number = {1-4},
pages = {473--493},
title = {{Intuitive 3D maps for MAV terrain exploration and obstacle avoidance}},
volume = {61},
year = {2011}
}
@inproceedings{Zhou2016,
abstract = {We present an algorithm for fast global registration of partially over-lapping 3D surfaces. The algorithm operates on candidate matches that cover the surfaces. A single objective is optimized to align the surfaces and disable false matches. The objective is defined densely over the surfaces and the optimiza-tion achieves tight alignment with no initialization. No correspondence updates or closest-point queries are performed in the inner loop. An extension of the al-gorithm can perform joint global registration of many partially overlapping sur-faces. Extensive experiments demonstrate that the presented approach matches or exceeds the accuracy of state-of-the-art global registration pipelines, while be-ing at least an order of magnitude faster. Remarkably, the presented approach is also faster than local refinement algorithms such as ICP. It provides the accu-racy achieved by well-initialized local refinement algorithms, without requiring an initialization and at lower computational cost.},
archivePrefix = {arXiv},
arxivId = {1311.2901},
author = {Zhou, Qian Yi and Park, Jaesik and Koltun, Vladlen},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-46475-6_47},
eprint = {1311.2901},
file = {:home/andreasziegler/Downloads/Fast Global Registration.pdf:pdf},
isbn = {9783319464749},
issn = {16113349},
pages = {766--782},
pmid = {4520227},
title = {{Fast global registration}},
volume = {9906 LNCS},
year = {2016}
}
@inproceedings{Zhou2013,
abstract = {We present an approach to reconstruction of detailed scene geometry $\backslash$nfrom range video. Range data produced by commodity handheld cameras suffers from $\backslash$nhigh-frequency errors and low-frequency distortion. Our approach deals with both $\backslash$nsources of error by reconstructing locally smooth scene fragments and letting $\backslash$nthese fragments deform in order to align to each other. We develop a volumetric $\backslash$nregistration formulation that leverages the smoothness of the deformation to $\backslash$nmake optimization practical for large scenes. Experimental results demonstrate $\backslash$nthat our approach substantially increases the fidelity of complex scene geometry $\backslash$nreconstructed with commodity handheld cameras.},
annote = {This paper presents an approach for dense scene reconstruction from range video produced by consumer-grade cameras. The approach partitions the video sequence into segments, uses frame-to-model integration to reconstruct locally precise scene fragments from each segment, establishes dense correspondences between oberlapping fragments, and optimizes a global objective that alighns the fragments. The optimization can subtly deform the fragments, thus correcting inconsistencies caused by low-frequency distortion in the input images.},
author = {Zhou, Qian Yi and Miller, Stephen and Koltun, Vladlen},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2013.65},
file = {:home/andreasziegler/Downloads/Elastic Fragments for Dense Scene Reconstruction.pdf:pdf},
isbn = {9781479928392},
issn = {1550-5499},
pages = {473--480},
title = {{Elastic fragments for dense scene reconstruction}},
year = {2013}
}
@INPROCEEDINGS{briales17CVPR,
     author = {Briales, Jesus and Gonzalez-Jimenez, Javier},
      month = {{{{jul}}}},
      title = {Convex Global 3D Registration with Lagrangian Duality},
  booktitle = {International Conference on Computer Vision and Pattern Recognition (CVPR)},
       year = {2017},
   location = {Honolulu, Hawaii}
}
